{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bone :  lowerArm_L_scale num :  44\n",
      "bone :  lowerArmTwist_L_scale num :  45\n",
      "bone :  hand_L num :  61\n",
      "bone :  lowerArmTwist_L num :  62\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ik/Desktop/zepeto')\n",
    "from a_python.rigging_class.rig_hier_maya_torch import *\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import scipy\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "import pytorch3d\n",
    "from a_python.utils.rot import _rot_base\n",
    "\n",
    "from pytorch3d.io import load_objs_as_meshes, save_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    FoVOrthographicCameras,\n",
    "    OpenGLOrthographicCameras,\n",
    "    FoVPerspectiveCameras, \n",
    "    PointLights, \n",
    "    RasterizationSettings, \n",
    "    MeshRenderer, \n",
    "    MeshRasterizer,  \n",
    "    SoftPhongShader,\n",
    "    SoftSilhouetteShader,\n",
    "    SoftPhongShader\n",
    ")\n",
    "from pytorch3d.renderer.mesh import rasterize_meshes\n",
    "from pytorch3d.renderer.mesh.rasterize_meshes import rasterize_meshes_python\n",
    "\n",
    "from pytorch3d.renderer.blending import BlendParams\n",
    "from pytorch3d.renderer.blending import sigmoid_alpha_blend, _sigmoid_alpha\n",
    "\n",
    "\n",
    "# Setup\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "_vertices = copy.deepcopy(vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사진 index\n",
    "\n",
    "idx_img = 11\n",
    "idx_img = 8\n",
    "\n",
    "# optimize parameters\n",
    "n_iter = 50\n",
    "alpha_loss_excede_mask = 10          # 마스크 넘어가는거에 얼마나 가중치 줄건지\n",
    "\n",
    "visualize_pcd = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_upperbody_maya_joints(keypts):\n",
    "    '''maya관절 길이비율대로 상체 조인트 추가 : chest upper, chest, spine'''\n",
    "    img_hip = (keypts[9,:2] + keypts[12,:2])/2\n",
    "    img_neck = (keypts[2,:2] + keypts[5,:2])/2\n",
    "    img_spine = (img_neck - img_hip) * len_joint_upper[-1] + img_hip\n",
    "    img_chest = (img_neck - img_hip) * (len_joint_upper[-1] + len_joint_upper[-2]) + img_hip\n",
    "    img_chsetupper = (img_neck - img_hip) * (len_joint_upper[-1] + len_joint_upper[-2] + len_joint_upper[-3])  + img_hip\n",
    "    return img_hip, img_neck, img_spine, img_chest, img_chsetupper\n",
    "\n",
    "def fitting_based_on_upperbody_joints(body, img_spine, img_hip, img_neck, _vertices):\n",
    "    '''img_upperbody_maya_joints 함수 결과 사용해서 메쉬 스케일링으로 상체 조인트위치 맞춤'''\n",
    "    # hip to spine 거리\n",
    "    _len_spine_maya = np.linalg.norm(body.head - body.childs[0].head) \n",
    "    _len_spine_img = np.linalg.norm(img_spine - img_hip)\n",
    "\n",
    "    # 상체 조인트 맞춤\n",
    "    _spine_trans = -(_len_spine_maya - _len_spine_img) * \\\n",
    "        ((-body.head + body.childs[0].head) / np.linalg.norm(body.head - body.childs[0].head))\n",
    "    body.childs[0].trans_head(_spine_trans, _vertices)\n",
    "    _scale_spine_hier = (np.linalg.norm(img_hip - img_neck) * len_joint_upper[-1]) / \\\n",
    "        (np.linalg.norm(body.childs[0].head - body.childs[0].childs[0].head))\n",
    "    body.childs[0].scale_iso_hier(_scale_spine_hier, _vertices)\n",
    "\n",
    "def _rot_base(axis, angle):\n",
    "    zero = torch.zeros_like(angle)\n",
    "    one = torch.ones_like(angle)\n",
    "    if axis == 'x':\n",
    "        return torch.tensor(\n",
    "            [\n",
    "                torch.stack([one, zero, zero]),\n",
    "                torch.stack([0, torch.cos(angle), -torch.sin(angle)]),\n",
    "                torch.stack([0, torch.sin(angle), torch.cos(angle)])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if axis == 'y':\n",
    "        return torch.tensor(\n",
    "            [\n",
    "                torch.stack([torch.cos(angle), zero, torch.sin(angle)]),\n",
    "                torch.stack([zero, one, zero]),\n",
    "                torch.stack([-torch.sin(angle), zero, torch.cos(angle)])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if axis == 'z':\n",
    "        return torch.stack(\n",
    "            [\n",
    "                torch.stack([torch.cos(angle), -torch.sin(angle), zero]),\n",
    "                torch.stack([torch.sin(angle), torch.cos(angle), zero]),\n",
    "                torch.stack([zero, zero, one]),\n",
    "            ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = idx_img\n",
    "path_img = \"/Users/ik/Downloads/test_set_new/{}/test_resized.png\".format(folder)\n",
    "path_json = \"/Users/ik/Downloads/test_set_new/{}/test_resized_keypoints.json\".format(folder)\n",
    "path_dp = \"/Users/ik/Downloads/test_set_new/{}/dp_dump.pkl\".format(folder)\n",
    "\n",
    "with open(path_json, 'r') as f:\n",
    "    data = json.load(f)\n",
    "with open(path_dp, 'rb') as f:\n",
    "    [img_seg, img_v, img_u,_] = pkl.load(f)\n",
    "h,w = img_seg.shape\n",
    "keypts = torch.tensor(data['people'][0]['pose_keypoints_2d']).reshape([-1,3])\n",
    "img = cv.imread(path_img)\n",
    "\n",
    "%matplotlib widget\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowerArm_L_scale\n"
     ]
    }
   ],
   "source": [
    "_vertices = copy.deepcopy(vertices)\n",
    "body = rig_class(65)\n",
    "print(body.childs[0].childs[0].childs[0].childs[1].childs[0].childs[0].childs[0].name)\n",
    "chestUpper_scale = body.childs[0].childs[0].childs[0]\n",
    "shoulder_L_scale = body.childs[0].childs[0].childs[0].childs[1]\n",
    "lowerarm_scale = body.childs[0].childs[0].childs[0].childs[1].childs[0].childs[0].childs[0]\n",
    "lowerarm_twist_scale = body.childs[0].childs[0].childs[0].childs[1].childs[0].childs[0].childs[0].childs[0]\n",
    "\n",
    "# chestUpper_scale.scale_iso_hier(5, _vertices)\n",
    "# shoulder_L_scale.scale_iso_hier(1.5, _vertices)\n",
    "# lowerarm_scale.scale_iso_hier(5, _vertices)\n",
    "# lowerarm_scale.rot(_rot_base('z', torch.tensor(math.pi/3)), _vertices, inplace=False)\n",
    "# lowerarm_twist_scale.scale_iso_hier(5, _vertices)\n",
    "shoulder_L_scale.rot(_rot_base('z', torch.tensor(math.pi/3)), _vertices, inplace=False)\n",
    "# lowerarm_twist_scale.rot(_rot_base('z', torch.tensor(math.pi/3)), _vertices, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerarm_twist_scale.weight_vertices_for_bone\n",
    "lowerarm_twist_scale.idx_vertices_for_bone\n",
    "\n",
    "_weight_sum = torch.zeros([vertices.shape[0]])\n",
    "tmp = body.concat_weights(_weight_sum)\n",
    "print(_weight_sum[8665])\n",
    "print(_weight_sum[8657])\n",
    "print(_weight_sum[8633])\n",
    "print(_weight_sum[8624])\n",
    "print(_weight_sum[7360])\n",
    "print(_weight_sum[7420])\n",
    "print(_weight_sum[7647])\n",
    "\n",
    "f_index = np.arange(_vertices.shape[0])[_weight_sum <0.8]\n",
    "print(f_index)\n",
    "print(_weight_sum[7432])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 02:02:43.396 Python[83125:14787965] TSM AdjustCapsLockLEDForKeyTransitionHandling - _ISSetPhysicalKeyboardCapsLockLED Inhibit\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "_list_joint = []\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "\n",
    "_vertices_opt = copy.deepcopy(_vertices)\n",
    "body_copy = copy.deepcopy(body)\n",
    "\n",
    "\n",
    "_vertices_draw = np.asarray(copy.deepcopy(_vertices_opt.detach()))\n",
    "\n",
    "pcd.points = o3d.utility.Vector3dVector(_vertices_draw)\n",
    "\n",
    "_color = np.zeros([9067,3])*np.array([0.5,0.3,1])\n",
    "\n",
    "# _color[_weight_sum<=0.8,:] = np.array([0,1,0])\n",
    "\n",
    "pcd.colors = o3d.utility.Vector3dVector(_color)\n",
    "\n",
    "_list_joint.append(pcd)\n",
    "body.draw_joint(_list_joint)\n",
    "o3d.visualization.draw_geometries(_list_joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_list_joint = []\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "\n",
    "_vertices_opt = copy.deepcopy(_vertices)\n",
    "body_copy = copy.deepcopy(body)\n",
    "\n",
    "\n",
    "_vertices_draw = np.asarray(copy.deepcopy(_vertices_opt.detach()))\n",
    "\n",
    "# _vertices_draw = np.asarray(copy.deepcopy(_vertices.detach()))\n",
    "pcd.points = o3d.utility.Vector3dVector(_vertices_draw)\n",
    "_color = np.ones([9067,3])*np.array([0.5,0.3,1])\n",
    "pcd.colors = o3d.utility.Vector3dVector(_color)\n",
    "# _pcd = o3d.geometry.PointCloud()\n",
    "# _pcd.points = o3d.utility.Vector3dVector(vertices)\n",
    "# _list_joint.append(_pcd)\n",
    "_list_joint.append(pcd)\n",
    "body.draw_joint(_list_joint)\n",
    "o3d.visualization.draw_geometries(_list_joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
